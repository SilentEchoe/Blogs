---
title: 了解提示工程
date: 2024-4-17 10:41:36
tags: [AI,学习笔记]
category: AI
---

### 什么是提示工程？

提示工程(Prompt Engineering)用于提升大语言模型(Large Language Model, LLM)在处理复杂任务场景的能力，比如问答或推理计算能力。这是一门比较新的学科，随着AI应用的爆发性增长而进入大众视野。

提示工程在与大模型交互，对接，以及理解大模型预言能力等方面发挥着重要作用，我们熟知的ChatGPT就使用了提示工程来提高多轮对话的效果。

比较现实的是，工程师个人难以拥有深度学习所需的算力，无法提供模型训练和微调所需的资源，在某些特定场景下提示工程可能是门槛较低的优化大模型方案之一。

提示词由四个要素组成：

**指令：**想要模型执行的任务

**上下文：**给模型提供一些额外的上下文信息，用于引导模型输出更优质的内容

**输入数据：**用户输入的内容或问题

**输出指示：**指定模型输出的类型或格式

> 展示一段代码
>
> 要求输出"hello word"
>
> 编程语言为Go语言

大模型输出:

```go
以下是一个简单的 Go 代码段，用于输出 “hello world”：
package main

import "fmt"

func main() {
    fmt.Println("hello world")
}
```

上例示例中，指令或任务是"展示一段代码"，输出数据为"要求输出'hello word'",输出指示为"编程语言为Go语言"。上例示例中并没有包含**上下文**，但是大模型依然输出了我们期望的内容，可见提示词并非上述元素都是必须的。同时通过大模型的输出，我们可以发现"要求输出'hello word'",被大模型输出为`fmt.Println("hello world")`,模型矫正了单词错误。

在使用提示词时，一般工程师会通过API调用的方式或直接与大模型进行交互，在这个阶段可以通过配置一些参数用来优化输出结果。不同参数对于输出的结果非常重要，常见的一些参数设置：

**Temperature**:这个参数值越小，模型返回的结果越精确，这个参数越大，模型返回的随机性越大。在一些需要精确结果的应用场景下可以将这个值调小，反之在一些创造性强的场景下，例如生成诗歌，编一个故事…可以适当通过调高参数值以丰富模型输出。

**Max Length**: 这个参数用于控制大模型Token输出，可以避免大模型生成冗长或无意义的响应。

**Stop Sequences：**用来控制大模型输出的另一种方式，是一个string类型，设置可以控制列表输出项等。

**Frequency Penalty:** 用来调整多轮对话中，某个词在模型输出中出现的次数，该参数越高，某个词再次出现的可能性就越小。

上例参数是大模型可调参数的一部分，具体可根据大模型[相关文档](https://open.bigmodel.cn/dev/api#glm-4)进行阅读，本文所有示例基于GLM-4，但不确保模型响应与本文示例保持一致。

在OpenAI官网提供的提示工程指南中提出了六个原则：

- 写出清晰的指令
- 提供参考文本
- 将复杂的任务拆分成简单的子任务
- 给模型'思考'的时间
- 使用外部工具
- 系统地测试变更



### 零样本提示和少样本提示

经过大量训练出来的大模型已经能够执行零样本任务，即不提供任何示例，模型依然会输出相对符合期望的结果，这源于RLHF技术在深度学习时让模型更好适应人类偏好。但在更复杂的场景或问题下，零样本下的大模型无法输出更优质的结果，这便衍生出少量样本提示来引导模型。

零样本提示：

```tex
输入："请用'槑雷'造句"

输出：我今天在网吧玩游戏，结果连续遇到槑雷的队友，真是让人哭笑不得。
```

少量样本提示：

```tex
输入: '槑雷'是一种生活用品，一个使用'槑雷'这个词的句子的例子是：在洗碗的时候使用槑雷，能让碗变得非常干净"

	   '雷槑'指一段非常好的代码，请用'雷槑'造句

输出:  编写程序时，我用了一段雷槑的代码，让整个程序运行效率大幅提升，性能检测结果让人非常满意。
```

我们通过上述例子可以观察到，'槑雷'这个人为臆造的词在零样本生成下可能词不达意，但是在少样本提示下，大模型通过示例已经学会了如何正确使用该词。

标签和格式也会对大模型的输出起作用：

```
输入： 你代码写的太好啦！// 夸赞
      你代码写的太差了！// 批评
      你的裙子真不错！//
      
输出：夸赞
```

即使是随机标签也会对输出有帮助，毕竟有总比没有好。

```
输入：这组数字中的奇数加起来是一个偶数：151、321、51、131、821、71、121。
输出：让我们将给定的奇数相加，并检查其和是否为偶数。
     151 + 321 + 51 + 131 + 821 + 71 + 121 = 1766
     现在，我们来确定这个结果是否为偶数。一个数如果可以被2整除，那么它就是偶数。在这种情况下，1766可以被2整除，因为其个位数是6（偶数的个位数总是0, 2, 4, 6, 或8）。
     因此，这些奇数相加的和1766确实是一个偶数。这符合数学规律，即两个奇数相加总是得到一个偶数（因为两个奇数相加，其个位数总是两个奇数个位数相加等于偶数的结果，从而使得和为偶数），所以多个奇数相加的和也有可能是偶数。在这个例子中，七个奇数相加得到了一个偶数。
```

可以拿计算器试一下，大模型这方面是反直觉的，用户可能认为基础的计算应该是百无一失的，实际上`151 + 321 + 51 + 131 + 821 + 71 + 121`并不等于 `1766`而是 `1677`，七个奇数相加怎么会得出偶数结果呢？这个结果与大模型后续输出的思考内容也是相悖的。

即使提供少样本提示也很难获得这种类型的推理问题的可靠响应。



### 思维链提示

当任务过于复杂，少样本提示无法起作用时。可以使用思维链(CoT)提示，有一个更简单的方式：

```
输入：151+321+51+131+121+71+821 结果是多少？是奇数还是偶数？让我们逐步思考
输出：我们可以把所有的数相加：151 + 321 + 51 + 131 + 121 + 71 + 821，最终结果是1667。
     1667不是2的倍数，因此它是一个奇数。
```

"让我们逐步思考"提示是一种自动化思维链展示，在没有太多的示例提供时它相当好用。假设你使用人工手动解析这一计算过程，也可能会输入错误信息(毕竟人类也会犯错，当然，现在大模型也会)而误导大模型。这种自动思维链的方式可以消除人工的方法，当然这种自动的过程也会出错，所以演示的多样性依旧重要：

Auto-CoT 两个阶段：

1.问题聚类：给问题划分为几个聚类

2.演示抽样，从每组数据中选出一个具有代表性的问题，并使用带有简单启发式的 Zero-Shot-CoT 生成其推理链。

简单的启发式方法可以是问题的长度（例如，60 个 tokens）和理由的步骤数（例如，5 个推理步骤）。这鼓励模型使用简单而准确的演示。





### 链式思考(CoT)提示

还记得最开始OpenAI推荐的六个原则吗？将复杂的任务拆解成简单的子任务。就像人类在面对上述计算题会将逐步数字逐步拆分，在将多个结果整合后给出最终答案。所谓的链式提示就是将子任务的提示词给语言模型。

> LLM 的一个常见用途是根据大型文本文档回答问题。想要更好阅读大文本文档，可以设计两个不同的提示，第一个提示负责提取相关引文以回答问题，第二个提示则以引文和原始文档为输入来回答给定的问题。换句话说，可以创建两个不同的提示来执行根据文档回答问题的任务。

提示词：

```
你是一个文档助手，可以根据文档回答问题，你的任务是从文档中提取核心论点，由####分隔。请用<></>输出内容。如果无法提取，请回答"我不知道"！
###
文档内容详情为：https://kubernetes.io/zh-cn/docs/concepts/overview/#why-you-need-kubernetes-and-what-can-it-do
###
```

输出：

```
为什么需要 Kubernetes，它能做什么？
Kubernetes 提供了弹性运行分布式系统的框架。
功能包括：服务发现和负载均衡、存储编排、自动部署和回滚、自动装箱计算、自我修复、密钥与配置管理、批处理执行、水平扩缩、IPv4/IPv6 双栈、为可扩展性设计。
Kubernetes 不是传统的 PaaS 系统，它保留了用户的选择权，有更高的灵活性。
Kubernetes 不限制支持的应用程序类型，不部署源代码，不提供应用程序级别服务，不是日志记录或警报的解决方案，不采用任何全面的机器配置或管理系统。Kubernetes 不仅仅是一个编排系统，它消除了编排的需要，通过独立可组合的控制过程，将当前状态驱动到预期状态。
```

然后将第一次的输出以提示词的方式作为第二个提示的输入：

```
你是一个文档助手，可以根据文档回答问题。你的任务是告知Kubernetes能做什么，由####分隔。请用<></>输出内容。如果无法提取，请回答"我不知道"！

###
Kubernetes 提供了弹性运行分布式系统的框架。
功能包括：服务发现和负载均衡、存储编排、自动部署和回滚、自动装箱计算、自我修复、密钥与配置管理、批处理执行、水平扩缩、IPv4/IPv6 双栈、为可扩展性设计。
Kubernetes 不是传统的 PaaS 系统，它保留了用户的选择权，有更高的灵活性。
Kubernetes 不限制支持的应用程序类型，不部署源代码，不提供应用程序级别服务，不是日志记录或警报的解决方案，不采用任何全面的机器配置或管理系统。Kubernetes 不仅仅是一个编排系统，它消除了编排的需要，通过独立可组合的控制过程，将当前状态驱动到预期状态。
###
```

输出：

```
Kubernetes 提供了弹性运行分布式系统的框架。功能包括：服务发现和负载均衡、存储编排、自动部署和回滚、自动装箱计算、自我修复、密钥与配置管理、批处理执行、水平扩缩、IPv4/IPv6 双栈、为可扩展性设计。Kubernetes 不仅仅是一个编排系统，它消除了编排的需要，通过独立可组合的控制过程，将当前状态驱动到预期状态。它不限制支持的应用程序类型，不部署源代码，不是传统的 PaaS 系统，保留了用户的选择权和灵活性。
```

链式提示在构建LLM驱动的对话助手时特别有用，它能在多轮对话中不断优化输出性能，在这个过程中也会涉及到提示词技术中的"生成知识提示"，可以人为地将一部分知识作为提示词输入给模型，从而优化质量。

基于链式思考提示，也衍生出思维树(ToT)框架引导模型将思维当作中间步骤来解决一些通用问题，这有点回归到数学，通过广度优先搜索或深度优先搜索来对每一步思维进行抽样，然后以多轮对话搜索树的方式来增强大模型的能力。

ToT提示词的例子如下(来源于[Hulbert ](https://github.com/dave1010/tree-of-thought-prompting))：

> 假设三位不同的专家来回答这个问题。
> 所有专家都写下他们思考这个问题的第一个步骤，然后与大家分享。
> 然后，所有专家都写下他们思考的下一个步骤并分享。
> 以此类推，直到所有专家写完他们思考的所有步骤。
> 只要大家发现有专家的步骤出错了，就让这位专家离开。
> 请问...



### 检索增强生成(RAG)

通用语言模型仅仅通过微调就可以完成一部分常见任务，本文中使用智谱GLM-4大模型在**自我一致性**和**零样本提示**下已经表现的超出预期，但是依旧无法完成复杂的知识密集形的任务。

检索增强生成(Retrieval Augmented Generation,RAG)用来优化这类知识密集形的任务。RAG把一个信息检索组件和文本生成模型结合在一起，可以简单理解为"给大模型联网"，以**生成知识提示**的方式来优化大模型的输出。同时RAG可以进行调整，而不需要对整个模型进行重新训练，这不仅节约了算力/时间等资源，也节约了成本。

RAG会先接受输出，按照输入检索出一组相关的资料文档，然后将这些文档作为上下文和输入的原始提示词结合，然后再输入给大模型得到最终输出。这样大模型可以不用重新训练也可以获取新的知识，这非常有效，同时也对传统的搜索引擎巨头提出挑战。有一些AI搜索的应用可以让用户提炼出更加准确的条目并且避免了广告。例如秘塔，必应等。

RAG已经是一种可行的方案，在知识密集型任务中越来越流行，LangChain文档中[Quickstart](https://python.langchain.com/docs/use_cases/question_answering/quickstart/)记录了如何帮助构建一个RAG应用。



### 后记

提示工程虽然是一门较新的学科，但它的发展速度(论文发布速度)却让人咂舌，即使不做AI应用相关的开发，作者本人也推荐大家看一下提示工程相关的资料，这也有助于提高输入质量，能从AI产品中获取更准确，能有更质量的输出。







### 学习资料

https://www.promptingguide.ai/zh

https://github.com/amazon-science/auto-cot

https://docs.anthropic.com/claude/docs/chain-prompts
