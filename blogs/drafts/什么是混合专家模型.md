DeepSeek R1 最先采用一种被称为"混合专家"的架构，可以把它想象成一个由众多小型专家模型组成的团队，每个专家擅长不同类型的任务，只有在需要时才各自上阵发挥作用。

> R1拥有6710亿个参数，是参数规模最大的模型之一。但由于采用了混合专家的架构，每次回答问题时实际参与计算的参数大约370亿。这意味着，R1在保证模型庞大知识容量的同时，大幅降低了单次推理所需的计算量。这种做法在减少计算复杂度和内存占用、提高了效率的同时，还能保证模型在推理、数学、代码等领域表现出色。

R1在训练方法上也不太一样，最初研发团队让模型经历一个"冷启动"阶段，用精心挑选的高质量示例来对基础模型(v3)进行微调。模型将会进入多个轮次的强化学习阶段，让R1与各种问题反复"练习"，其中会使用人工干预来做奖惩。

> R1拥有6710亿个参数，是参数规模最大的模型之一。但由于采用了混合专家的架构，每次回答问题时实际参与计算的参数大约370亿。这意味着，R1在保证模型庞大知识容量的同时，大幅降低了单次推理所需的计算量。这种做法在减少计算复杂度和内存占用、提高了效率的同时，还能保证模型在推理、数学、代码等领域表现出色。

R1在处理复杂问题上会解释自己的思路，向用户解释自己的推理过程。



